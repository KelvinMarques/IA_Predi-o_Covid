{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1DoArZuaG_Zz0f1GNv6WN4cQci_PTKbpa",
      "authorship_tag": "ABX9TyPs92BaN62uQ2jpi/6ZBfVn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KelvinMarques/IA_predict_covid/blob/main/GS_IA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np # linear algebra\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "n8SmP3eYdqgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJJC3UxUdkA-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/datasets/plameneduardo/sarscov2-ctscan-dataset"
      ],
      "metadata": {
        "id": "t7JwSuuHdvcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir =  '/content/Dataset'\n",
        "img_height, img_width = 224,224\n",
        "batch_size = 64\n",
        "\n",
        "class_names = ['Covid', 'Non-Covid']\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  labels='inferred',\n",
        "  label_mode='binary',\n",
        "  class_names=class_names,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  shuffle=True,\n",
        "  interpolation='nearest',\n",
        "  batch_size=batch_size)\n",
        "\n",
        "valid_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  labels='inferred',\n",
        "  label_mode='binary',\n",
        "  class_names=class_names,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  shuffle=True,\n",
        "  interpolation='nearest',\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "wxBQqIQllExO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6afb91cf-752f-4477-ff08-6f8591e7720f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1284 files belonging to 2 classes.\n",
            "Using 1028 files for training.\n",
            "Found 1284 files belonging to 2 classes.\n",
            "Using 256 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2QyEN1ab0o9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "039e5e54-fab1-4c05-b19f-6eaa3cb47c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image preprocessingÂ¶\n"
      ],
      "metadata": {
        "id": "3UdQy6vMC1iS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rescale = tf.keras.Sequential([\n",
        "    layers.Rescaling(1./255, input_shape=[img_height, img_width, 3])\n",
        "])"
      ],
      "metadata": {
        "id": "6vuwr0GLC3DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model definition\n"
      ],
      "metadata": {
        "id": "j_ACPBDnC65n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "\n",
        "    rescale,\n",
        "\n",
        "    # First Convolutional Block\n",
        "    layers.Conv2D(filters=32, kernel_size=5, activation=\"relu\", padding='same'),\n",
        "    layers.MaxPool2D(),\n",
        "\n",
        "    # Second Convolutional Block\n",
        "    layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n",
        "    layers.MaxPool2D(),\n",
        "\n",
        "    # Third Convolutional Block\n",
        "    layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n",
        "    layers.MaxPool2D(),\n",
        "\n",
        "    # Classifier Head\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(units=128, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(units=64, activation=\"relu\"),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(units=32, activation=\"relu\"),\n",
        "    layers.Dense(units=1, activation=\"sigmoid\"),\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "bSM8JytvC7i6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac2d3742-7a0c-4053-b152-a5d2718daccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 224, 224, 32)      2432      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 112, 112, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 112, 112, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 56, 56, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 28, 28, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               12845184  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12950337 (49.40 MB)\n",
            "Trainable params: 12950337 (49.40 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting"
      ],
      "metadata": {
        "id": "sGesn747C_KZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds_preprocess = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "valid_ds_preprocess = valid_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['binary_accuracy'],\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds_preprocess,\n",
        "    validation_data=valid_ds_preprocess,\n",
        "    epochs=50,\n",
        "    verbose=1,\n",
        "    callbacks=[callback],\n",
        ")"
      ],
      "metadata": {
        "id": "Pdu8uOlmDAno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d6e185-9939-4515-9027-bf742c26efab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "17/17 [==============================] - 163s 9s/step - loss: 0.2573 - binary_accuracy: 0.8765 - val_loss: 0.1117 - val_binary_accuracy: 0.9766\n",
            "Epoch 2/50\n",
            "17/17 [==============================] - 152s 9s/step - loss: 0.1518 - binary_accuracy: 0.9747 - val_loss: 0.1083 - val_binary_accuracy: 0.9766\n",
            "Epoch 3/50\n",
            "17/17 [==============================] - 161s 9s/step - loss: 0.1309 - binary_accuracy: 0.9747 - val_loss: 0.1082 - val_binary_accuracy: 0.9766\n",
            "Epoch 4/50\n",
            "17/17 [==============================] - 152s 9s/step - loss: 0.1308 - binary_accuracy: 0.9747 - val_loss: 0.1058 - val_binary_accuracy: 0.9766\n",
            "Epoch 5/50\n",
            "17/17 [==============================] - 175s 10s/step - loss: 0.1340 - binary_accuracy: 0.9737 - val_loss: 0.1062 - val_binary_accuracy: 0.9766\n",
            "Epoch 6/50\n",
            "17/17 [==============================] - 173s 10s/step - loss: 0.1299 - binary_accuracy: 0.9747 - val_loss: 0.1058 - val_binary_accuracy: 0.9766\n",
            "Epoch 7/50\n",
            "17/17 [==============================] - 172s 10s/step - loss: 0.1352 - binary_accuracy: 0.9747 - val_loss: 0.1164 - val_binary_accuracy: 0.9766\n",
            "Epoch 8/50\n",
            "17/17 [==============================] - 165s 10s/step - loss: 0.1222 - binary_accuracy: 0.9747 - val_loss: 0.1195 - val_binary_accuracy: 0.9766\n",
            "Epoch 9/50\n",
            "17/17 [==============================] - 162s 10s/step - loss: 0.1270 - binary_accuracy: 0.9747 - val_loss: 0.1057 - val_binary_accuracy: 0.9766\n",
            "Epoch 10/50\n",
            "17/17 [==============================] - 165s 10s/step - loss: 0.1186 - binary_accuracy: 0.9747 - val_loss: 0.1052 - val_binary_accuracy: 0.9766\n",
            "Epoch 11/50\n",
            "17/17 [==============================] - 164s 10s/step - loss: 0.1213 - binary_accuracy: 0.9747 - val_loss: 0.1102 - val_binary_accuracy: 0.9766\n",
            "Epoch 12/50\n",
            "17/17 [==============================] - 172s 10s/step - loss: 0.1255 - binary_accuracy: 0.9747 - val_loss: 0.1152 - val_binary_accuracy: 0.9766\n",
            "Epoch 13/50\n",
            "17/17 [==============================] - 173s 10s/step - loss: 0.1303 - binary_accuracy: 0.9747 - val_loss: 0.1059 - val_binary_accuracy: 0.9766\n",
            "Epoch 14/50\n",
            "17/17 [==============================] - 161s 10s/step - loss: 0.1275 - binary_accuracy: 0.9747 - val_loss: 0.1006 - val_binary_accuracy: 0.9766\n",
            "Epoch 15/50\n",
            "17/17 [==============================] - 173s 10s/step - loss: 0.1123 - binary_accuracy: 0.9747 - val_loss: 0.0958 - val_binary_accuracy: 0.9766\n",
            "Epoch 16/50\n",
            "17/17 [==============================] - 160s 9s/step - loss: 0.1038 - binary_accuracy: 0.9747 - val_loss: 0.1090 - val_binary_accuracy: 0.9766\n",
            "Epoch 17/50\n",
            "17/17 [==============================] - 173s 10s/step - loss: 0.0863 - binary_accuracy: 0.9747 - val_loss: 0.1108 - val_binary_accuracy: 0.9766\n",
            "Epoch 18/50\n",
            "17/17 [==============================] - 163s 10s/step - loss: 0.0822 - binary_accuracy: 0.9747 - val_loss: 0.1006 - val_binary_accuracy: 0.9766\n",
            "Epoch 19/50\n",
            "17/17 [==============================] - 173s 10s/step - loss: 0.0781 - binary_accuracy: 0.9747 - val_loss: 0.1037 - val_binary_accuracy: 0.9766\n",
            "Epoch 20/50\n",
            "17/17 [==============================] - 163s 9s/step - loss: 0.0561 - binary_accuracy: 0.9747 - val_loss: 0.1108 - val_binary_accuracy: 0.9766\n",
            "Epoch 21/50\n",
            "17/17 [==============================] - 160s 9s/step - loss: 0.0561 - binary_accuracy: 0.9747 - val_loss: 0.1274 - val_binary_accuracy: 0.9766\n",
            "Epoch 22/50\n",
            "17/17 [==============================] - 162s 10s/step - loss: 0.0426 - binary_accuracy: 0.9747 - val_loss: 0.1369 - val_binary_accuracy: 0.9766\n",
            "Epoch 23/50\n",
            "17/17 [==============================] - 173s 10s/step - loss: 0.0401 - binary_accuracy: 0.9747 - val_loss: 0.1300 - val_binary_accuracy: 0.9766\n",
            "Epoch 24/50\n",
            "17/17 [==============================] - 159s 9s/step - loss: 0.0338 - binary_accuracy: 0.9844 - val_loss: 0.1448 - val_binary_accuracy: 0.9727\n",
            "Epoch 25/50\n",
            "17/17 [==============================] - 174s 10s/step - loss: 0.0295 - binary_accuracy: 0.9844 - val_loss: 0.1902 - val_binary_accuracy: 0.9805\n",
            "Epoch 26/50\n",
            "17/17 [==============================] - 163s 9s/step - loss: 0.0331 - binary_accuracy: 0.9796 - val_loss: 0.1228 - val_binary_accuracy: 0.9766\n",
            "Epoch 27/50\n",
            "17/17 [==============================] - 160s 10s/step - loss: 0.0223 - binary_accuracy: 0.9825 - val_loss: 0.1897 - val_binary_accuracy: 0.9727\n",
            "Epoch 28/50\n",
            "17/17 [==============================] - 166s 10s/step - loss: 0.0203 - binary_accuracy: 0.9835 - val_loss: 0.2508 - val_binary_accuracy: 0.9727\n",
            "Epoch 29/50\n",
            "17/17 [==============================] - 174s 10s/step - loss: 0.0249 - binary_accuracy: 0.9825 - val_loss: 0.2365 - val_binary_accuracy: 0.9766\n",
            "Epoch 30/50\n",
            "17/17 [==============================] - 162s 9s/step - loss: 0.0232 - binary_accuracy: 0.9893 - val_loss: 0.2169 - val_binary_accuracy: 0.9727\n",
            "Epoch 31/50\n",
            "17/17 [==============================] - 159s 9s/step - loss: 0.0152 - binary_accuracy: 0.9951 - val_loss: 0.2890 - val_binary_accuracy: 0.9727\n",
            "Epoch 32/50\n",
            "17/17 [==============================] - 169s 10s/step - loss: 0.0112 - binary_accuracy: 0.9951 - val_loss: 0.2939 - val_binary_accuracy: 0.9766\n",
            "Epoch 33/50\n",
            "17/17 [==============================] - 163s 10s/step - loss: 0.0120 - binary_accuracy: 0.9942 - val_loss: 0.2828 - val_binary_accuracy: 0.9688\n",
            "Epoch 34/50\n",
            "17/17 [==============================] - 169s 10s/step - loss: 0.0152 - binary_accuracy: 0.9942 - val_loss: 0.3239 - val_binary_accuracy: 0.9727\n",
            "Epoch 35/50\n",
            "17/17 [==============================] - 160s 9s/step - loss: 0.0152 - binary_accuracy: 0.9922 - val_loss: 0.3563 - val_binary_accuracy: 0.9766\n",
            "Epoch 36/50\n",
            "17/17 [==============================] - 172s 10s/step - loss: 0.0102 - binary_accuracy: 0.9971 - val_loss: 0.2915 - val_binary_accuracy: 0.9727\n",
            "Epoch 37/50\n",
            "17/17 [==============================] - 174s 10s/step - loss: 0.0087 - binary_accuracy: 0.9942 - val_loss: 0.2782 - val_binary_accuracy: 0.9688\n",
            "Epoch 38/50\n",
            "17/17 [==============================] - 159s 9s/step - loss: 0.0156 - binary_accuracy: 0.9932 - val_loss: 0.2231 - val_binary_accuracy: 0.9727\n",
            "Epoch 39/50\n",
            "17/17 [==============================] - 162s 9s/step - loss: 0.0104 - binary_accuracy: 0.9981 - val_loss: 0.3581 - val_binary_accuracy: 0.9727\n",
            "Epoch 40/50\n",
            "17/17 [==============================] - 158s 9s/step - loss: 0.0149 - binary_accuracy: 0.9942 - val_loss: 0.3017 - val_binary_accuracy: 0.9688\n",
            "Epoch 41/50\n",
            "17/17 [==============================] - 169s 10s/step - loss: 0.0110 - binary_accuracy: 0.9961 - val_loss: 0.3232 - val_binary_accuracy: 0.9648\n",
            "Epoch 42/50\n",
            "17/17 [==============================] - 172s 10s/step - loss: 0.0108 - binary_accuracy: 0.9961 - val_loss: 0.3226 - val_binary_accuracy: 0.9688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results\n",
        "\n",
        "###Confusion matrix\n"
      ],
      "metadata": {
        "id": "IhRuKNTmDHcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "CLASSES = train_ds.class_names\n",
        "probabilities = model.predict(valid_ds_preprocess)\n",
        "\n",
        "predictions = [1 if i >0.5 else 0 for i in probabilities]\n",
        "unbatched_valid_ds_preprocess = valid_ds_preprocess.unbatch()\n",
        "labels_valid = [int(i[1]) for i in unbatched_valid_ds_preprocess]\n",
        "list_labels_predictions = np.vstack((labels_valid,predictions)).T\n",
        "conf_matrix = np.zeros([2,2])\n",
        "\n",
        "for i,j in list_labels_predictions:\n",
        "    conf_matrix[i,j] +=1\n",
        "\n",
        "accuracy = accuracy_score(labels_valid, predictions)\n",
        "f1_score = conf_matrix[1,1]/(conf_matrix[1,1] + ((conf_matrix[0,1] + conf_matrix[1,0])/2))\n",
        "print('Val Accuracy: %.2f' % accuracy)\n",
        "print('False positive: %.2f' % (conf_matrix[0,1]/len(predictions)))\n",
        "print('False negative: %.2f' % (conf_matrix[1,0]/len(predictions)))\n",
        "print('F1-score: %.2f' % (f1_score))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.Blues)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        "\n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "\n",
        "ax.set_yticks([0,1])\n",
        "ax.set_yticklabels(CLASSES)\n",
        "ax.set_xticks([0,1])\n",
        "ax.set_xticklabels(CLASSES)\n",
        "plt.title('Confusion Matrix', fontsize=18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ufL2bcIdDLMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Categorization resultsÂ¶\n"
      ],
      "metadata": {
        "id": "IFDu1OzrDaNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows, cols = 3, 3\n",
        "dataset = valid_ds_preprocess\n",
        "dataset = dataset.unbatch().batch(rows*cols)\n",
        "batch = iter(dataset)"
      ],
      "metadata": {
        "id": "SCt--vE4Dc5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = next(batch)\n",
        "probabilities = model.predict(img)\n",
        "fig, ax = plt.subplots(rows, cols, figsize=(10, 10))\n",
        "idx = 0\n",
        "for i in range(rows):\n",
        "    for j in range(cols):\n",
        "        predictions = (probabilities[idx] > 0.5).astype(\"int32\")\n",
        "        if CLASSES[int(label[idx][0])] != CLASSES[predictions[0]]:\n",
        "            title_color = 'red'\n",
        "        else:\n",
        "            title_color = 'black'\n",
        "\n",
        "        ax[i,j].set_title(CLASSES[int(label[idx][0])] + ' -> ' + CLASSES[predictions[0]], color=title_color)\n",
        "        ax[i,j].imshow(img[idx].numpy())\n",
        "        ax[i,j].xaxis.set_major_locator(ticker.NullLocator())\n",
        "        ax[i,j].yaxis.set_major_locator(ticker.NullLocator())\n",
        "        idx +=1"
      ],
      "metadata": {
        "id": "1Qpx2K9KDj2N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}